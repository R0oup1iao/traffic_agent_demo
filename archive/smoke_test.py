"""
äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ Smoke Test Demo
==============================
æœ¬æ–‡ä»¶æ¼”ç¤º LangGraph + OpenAI API + MCP çš„åŸºæœ¬é›†æˆæ–¹å¼ã€‚

æŠ€æœ¯æ ˆ:
- LangGraph: å®ç°æœ‰å‘å¾ªç¯å›¾ï¼ˆDCGï¼‰è®¤çŸ¥æµ
- OpenAI API: è°ƒç”¨ GPT æ¨¡å‹è¿›è¡Œæ¨ç†
- MCP Client: è¿æ¥é«˜å¾·åœ°å›¾ MCP Server è·å–è·¯å¾„è§„åˆ’èƒ½åŠ›
- FastAPI: æä¾› RESTful API æ¥å£ï¼ˆç¤ºä¾‹ä»£ç ï¼‰

ä½¿ç”¨å‰è¯·å®‰è£…ä¾èµ–:
    pip install langgraph langchain-openai mcp httpx pydantic fastapi uvicorn

é…ç½®ç¯å¢ƒå˜é‡:
    OPENAI_API_KEY=your_openai_api_key
    AMAP_API_KEY=your_amap_api_key (é«˜å¾·åœ°å›¾å¼€æ”¾å¹³å°ç”³è¯·)

è¿è¡Œæ–¹å¼:
    python smoke_test.py
"""

import os
import json
import asyncio
from typing import TypedDict, Annotated, Literal
from dataclasses import dataclass

# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€é…ç½®
# ============================================================

# OpenAI API é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
AMAP_API_KEY = os.getenv("AMAP_API_KEY", "your-amap-key-here")

# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šLangGraph æ™ºèƒ½ä½“å®šä¹‰
# ============================================================

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# å®šä¹‰æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆå¯¹åº”è®ºæ–‡ä¸­çš„çŠ¶æ€ç©ºé—´ Sï¼‰
class AgentState(TypedDict):
    """
    æ™ºèƒ½ä½“çš„å…¨å±€çŠ¶æ€å­—å…¸ï¼Œå¯¹åº”è®ºæ–‡å…¬å¼ï¼š
    S = {G_flow, E_alert, M_context, P_candidate, F_feedback, Î›}
    """
    # ç”¨æˆ·è¾“å…¥çš„å‡ºè¡Œè¯·æ±‚
    user_request: str
    # èµ·ç‚¹å’Œç»ˆç‚¹
    origin: str
    destination: str
    # å½“å‰äº¤é€šæ€åŠ¿ï¼ˆç®€åŒ–ä¸ºæ–‡æœ¬æè¿°ï¼‰
    traffic_status: str
    # å€™é€‰å‡ºè¡Œæ–¹æ¡ˆ
    candidate_plans: list[dict]
    # æ¨èç»“æœ
    recommendation: str
    # åæ€è¯„ä¼°ç»“æœ
    reflection_score: float
    # å¯¹è¯å†å²
    messages: list
    # å½“å‰æ­¥éª¤
    current_step: str


def create_traffic_guidance_agent():
    """
    åˆ›å»ºäº¤é€šè¯±å¯¼æ™ºèƒ½ä½“çš„ LangGraph å›¾ç»“æ„ã€‚
    
    å®ç°è®ºæ–‡ä¸­æè¿°çš„æœ‰å‘å¾ªç¯å›¾ï¼ˆDCGï¼‰ç»“æ„ï¼š
    æ„ŸçŸ¥èŠ‚ç‚¹ -> è§„åˆ’å†³ç­–èŠ‚ç‚¹ -> åæ€èŠ‚ç‚¹ -> (å¾ªç¯å›è§„åˆ’æˆ–è¾“å‡º)
    """
    
    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(
        model="gpt-4o-mini",  # ä½¿ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        api_key=OPENAI_API_KEY,
        temperature=0.7
    )
    
    # -------------------- èŠ‚ç‚¹å®šä¹‰ --------------------
    
    def perception_node(state: AgentState) -> AgentState:
        """
        æ„ŸçŸ¥ä¸ä¸°å¯ŒèŠ‚ç‚¹ (Perception & Enrichment Node)
        
        è´Ÿè´£ä»å¤šæºå¼‚æ„æ•°æ®ä¸­æå–å½“å‰æ€åŠ¿ç‰¹å¾ï¼Œè°ƒç”¨ MCP æ¥å£è·å–å®æ—¶äº¤é€šä¿¡æ¯ã€‚
        """
        print("\nğŸ” [æ„ŸçŸ¥èŠ‚ç‚¹] æ­£åœ¨è·å–äº¤é€šæ€åŠ¿ä¿¡æ¯...")
        
        # æ¨¡æ‹Ÿè°ƒç”¨ MCP è·å–äº¤é€šçŠ¶æ€ï¼ˆå®é™…åº”é€šè¿‡ MCP Client è°ƒç”¨é«˜å¾· APIï¼‰
        # è¿™é‡Œç®€åŒ–ä¸ºæ¨¡æ‹Ÿæ•°æ®
        traffic_info = simulate_traffic_status(state["origin"], state["destination"])
        
        state["traffic_status"] = traffic_info
        state["current_step"] = "perception_complete"
        state["messages"].append(
            AIMessage(content=f"[æ„ŸçŸ¥èŠ‚ç‚¹] å·²è·å–äº¤é€šæ€åŠ¿ï¼š{traffic_info}")
        )
        
        return state
    
    def planning_node(state: AgentState) -> AgentState:
        """
        è§„åˆ’å†³ç­–èŠ‚ç‚¹ (Planning Node)
        
        åŸºäºå½“å‰çŠ¶æ€è°ƒç”¨ CDHGNN æ¨èæ¨¡å‹ç”Ÿæˆå€™é€‰å‡ºè¡Œæ–¹æ¡ˆã€‚
        è¿™é‡Œä½¿ç”¨ LLM æ¨¡æ‹Ÿ CDHGNN çš„æ¨èé€»è¾‘ã€‚
        """
        print("\nğŸ“‹ [è§„åˆ’èŠ‚ç‚¹] æ­£åœ¨ç”Ÿæˆå‡ºè¡Œæ–¹æ¡ˆ...")
        
        # æ„å»º promptï¼Œæ¨¡æ‹Ÿè°ƒç”¨ CDHGNN
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªäº¤é€šå‡ºè¡Œæ¨èä¸“å®¶ã€‚åŸºäºç”¨æˆ·çš„å‡ºè¡Œè¯·æ±‚å’Œå½“å‰äº¤é€šæ€åŠ¿ï¼Œ
        è¯·ç”Ÿæˆ 3 ä¸ªå€™é€‰å‡ºè¡Œæ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼šäº¤é€šæ–¹å¼ã€é¢„ä¼°æ—¶é—´ã€é¢„ä¼°è´¹ç”¨ã€æ¨èç†ç”±ã€‚
        
        è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        [
          {"mode": "åœ°é“", "time": "30åˆ†é’Ÿ", "cost": "5å…ƒ", "reason": "..."},
          ...
        ]
        """
        
        user_prompt = f"""
        å‡ºè¡Œè¯·æ±‚ï¼šä» {state["origin"]} åˆ° {state["destination"]}
        å½“å‰äº¤é€šæ€åŠ¿ï¼š{state["traffic_status"]}
        ç”¨æˆ·åŸå§‹éœ€æ±‚ï¼š{state["user_request"]}
        """
        
        response = llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        
        # è§£æå“åº”ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        try:
            # å°è¯•æå– JSON
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            plans = json.loads(content.strip())
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            plans = [
                {"mode": "åœ°é“", "time": "35åˆ†é’Ÿ", "cost": "5å…ƒ", "reason": "é¿å¼€åœ°é¢æ‹¥å µ"},
                {"mode": "æ‰“è½¦", "time": "45åˆ†é’Ÿ", "cost": "50å…ƒ", "reason": "é—¨åˆ°é—¨æœåŠ¡"},
                {"mode": "å…¬äº¤+åœ°é“", "time": "40åˆ†é’Ÿ", "cost": "4å…ƒ", "reason": "ç»æµå®æƒ "}
            ]
        
        state["candidate_plans"] = plans
        state["current_step"] = "planning_complete"
        state["messages"].append(
            AIMessage(content=f"[è§„åˆ’èŠ‚ç‚¹] å·²ç”Ÿæˆ {len(plans)} ä¸ªå€™é€‰æ–¹æ¡ˆ")
        )
        
        return state
    
    def reflection_node(state: AgentState) -> AgentState:
        """
        è‡ªæˆ‘åæ€èŠ‚ç‚¹ (Reflection Node)
        
        è¯„ä¼°è§„åˆ’æ–¹æ¡ˆçš„å¯è¡Œæ€§ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨å®‰å…¨éšæ‚£æˆ–æ•ˆç‡é—®é¢˜ã€‚
        å¦‚æœè¯„ä¼°ä¸é€šè¿‡ï¼Œå°†è§¦å‘å¾ªç¯å›è§„åˆ’èŠ‚ç‚¹ã€‚
        """
        print("\nğŸ¤” [åæ€èŠ‚ç‚¹] æ­£åœ¨è¯„ä¼°æ–¹æ¡ˆå¯è¡Œæ€§...")
        
        # ä½¿ç”¨ LLM è¿›è¡Œåæ€è¯„ä¼°
        reflection_prompt = f"""
        è¯·è¯„ä¼°ä»¥ä¸‹å‡ºè¡Œæ–¹æ¡ˆçš„å¯è¡Œæ€§ï¼ˆ0-1åˆ†ï¼‰ï¼š
        
        å‡ºè¡Œéœ€æ±‚ï¼šä» {state["origin"]} åˆ° {state["destination"]}
        äº¤é€šæ€åŠ¿ï¼š{state["traffic_status"]}
        å€™é€‰æ–¹æ¡ˆï¼š{json.dumps(state["candidate_plans"], ensure_ascii=False)}
        
        è¯·ç»™å‡ºç»¼åˆè¯„åˆ†ï¼ˆ0-1ä¹‹é—´çš„å°æ•°ï¼‰ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚
        è¿”å›æ ¼å¼ï¼š{{"score": 0.85, "reason": "..."}}
        """
        
        response = llm.invoke([HumanMessage(content=reflection_prompt)])
        
        try:
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            result = json.loads(content.strip())
            score = result.get("score", 0.8)
        except:
            score = 0.85  # é»˜è®¤é€šè¿‡
        
        state["reflection_score"] = score
        state["current_step"] = "reflection_complete"
        state["messages"].append(
            AIMessage(content=f"[åæ€èŠ‚ç‚¹] æ–¹æ¡ˆè¯„åˆ†ï¼š{score:.2f}")
        )
        
        return state
    
    def output_node(state: AgentState) -> AgentState:
        """
        è¾“å‡ºèŠ‚ç‚¹ (Output Node)
        
        ç”Ÿæˆæœ€ç»ˆçš„äººæ€§åŒ–æ¨èå»ºè®®ã€‚
        """
        print("\nâœ… [è¾“å‡ºèŠ‚ç‚¹] æ­£åœ¨ç”Ÿæˆæ¨èå»ºè®®...")
        
        # é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ
        best_plan = state["candidate_plans"][0] if state["candidate_plans"] else {}
        
        output_prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ®µç®€æ´ã€å‹å¥½çš„å‡ºè¡Œå»ºè®®ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š
        
        èµ·ç‚¹ï¼š{state["origin"]}
        ç»ˆç‚¹ï¼š{state["destination"]}
        äº¤é€šæ€åŠ¿ï¼š{state["traffic_status"]}
        æ¨èæ–¹æ¡ˆï¼š{json.dumps(best_plan, ensure_ascii=False)}
        """
        
        response = llm.invoke([HumanMessage(content=output_prompt)])
        
        state["recommendation"] = response.content
        state["current_step"] = "complete"
        state["messages"].append(
            AIMessage(content=f"[è¾“å‡ºèŠ‚ç‚¹] æ¨èå®Œæˆ")
        )
        
        return state
    
    # -------------------- æ¡ä»¶è¾¹å®šä¹‰ --------------------
    
    def should_retry(state: AgentState) -> Literal["planning", "output"]:
        """
        æ¡ä»¶è¾¹ï¼šæ ¹æ®åæ€è¯„åˆ†å†³å®šæ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’
        
        è¿™å®ç°äº†è®ºæ–‡ä¸­çš„"å¾ªç¯çŠ¶æ€è½¬ç§»"æœºåˆ¶ï¼š
        å½“åæ€èŠ‚ç‚¹é©³å›åˆå§‹æ–¹æ¡ˆæ—¶ï¼Œæ§åˆ¶æµå°†æ²¿åå‘è¾¹è·³è½¬å›è§„åˆ’èŠ‚ç‚¹ã€‚
        """
        if state["reflection_score"] < 0.6:
            print("âš ï¸ æ–¹æ¡ˆè¯„åˆ†è¿‡ä½ï¼Œè§¦å‘é‡æ–°è§„åˆ’...")
            return "planning"
        return "output"
    
    # -------------------- æ„å»ºå›¾ --------------------
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("perception", perception_node)
    workflow.add_node("planning", planning_node)
    workflow.add_node("reflection", reflection_node)
    workflow.add_node("output", output_node)
    
    # æ·»åŠ è¾¹ï¼ˆå®ç° DCG ç»“æ„ï¼‰
    workflow.add_edge(START, "perception")      # å…¥å£ -> æ„ŸçŸ¥
    workflow.add_edge("perception", "planning") # æ„ŸçŸ¥ -> è§„åˆ’
    workflow.add_edge("planning", "reflection") # è§„åˆ’ -> åæ€
    
    # æ¡ä»¶è¾¹ï¼šåæ€ -> è§„åˆ’ï¼ˆå¾ªç¯ï¼‰æˆ– è¾“å‡º
    workflow.add_conditional_edges(
        "reflection",
        should_retry,
        {
            "planning": "planning",
            "output": "output"
        }
    )
    
    workflow.add_edge("output", END)  # è¾“å‡º -> ç»“æŸ
    
    # ç¼–è¯‘å›¾
    app = workflow.compile()
    
    return app


def simulate_traffic_status(origin: str, destination: str) -> str:
    """
    æ¨¡æ‹Ÿäº¤é€šæ€åŠ¿è·å–ï¼ˆå®é™…åº”é€šè¿‡ MCP è°ƒç”¨é«˜å¾· APIï¼‰
    """
    # æ¨¡æ‹Ÿä¸€äº›å¼‚å¸¸æ€åŠ¿
    import random
    scenarios = [
        "å½“å‰è·¯å†µæ­£å¸¸ï¼Œé¢„è®¡é€šè¡Œé¡ºç•…",
        "ä¸œä¸‰ç¯å‘ç”Ÿäº¤é€šäº‹æ•…ï¼Œå±€éƒ¨æ‹¥å µä¸¥é‡ï¼Œå»ºè®®ç»•è¡Œ",
        "å—æš´é›¨å½±å“ï¼Œéƒ¨åˆ†è·¯æ®µç§¯æ°´ï¼Œåœ°é¢äº¤é€šå—é˜»",
        "æ—©é«˜å³°æ—¶æ®µï¼Œä¸»å¹²é“è½¦æµé‡å¤§ï¼Œåœ°é“å®¢æµå¯†é›†"
    ]
    return random.choice(scenarios)


# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šMCP Client ç¤ºä¾‹ï¼ˆè¿æ¥é«˜å¾·åœ°å›¾ MCP Serverï¼‰
# ============================================================

async def demo_mcp_client():
    """
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ MCP Client è¿æ¥é«˜å¾·åœ°å›¾ MCP Serverã€‚
    
    æ³¨æ„ï¼šå®é™…ä½¿ç”¨éœ€è¦ï¼š
    1. å®‰è£…é«˜å¾·åœ°å›¾ MCP Serverï¼ˆå¦‚ amap-mcp-serverï¼‰
    2. é…ç½® AMAP_API_KEY ç¯å¢ƒå˜é‡
    3. å¯åŠ¨ MCP Server
    
    è¿™é‡Œä»…å±•ç¤ºä»£ç ç»“æ„ï¼Œä¸å®é™…è°ƒç”¨ã€‚
    """
    print("\n" + "="*60)
    print("MCP Client ç¤ºä¾‹ä»£ç ")
    print("="*60)
    
    mcp_example_code = '''
# MCP Client ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦ MCP Server è¿è¡Œï¼‰

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

async def call_amap_mcp():
    """é€šè¿‡ MCP è°ƒç”¨é«˜å¾·åœ°å›¾è·¯å¾„è§„åˆ’"""
    
    # é…ç½® MCP Server è¿æ¥å‚æ•°
    server_params = StdioServerParameters(
        command="npx",
        args=["-y", "@agentic/amap-mcp-server"],
        env={"AMAP_API_KEY": os.getenv("AMAP_API_KEY")}
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # åˆå§‹åŒ–è¿æ¥
            await session.initialize()
            
            # åˆ—å‡ºå¯ç”¨å·¥å…·
            tools = await session.list_tools()
            print(f"å¯ç”¨å·¥å…·: {[t.name for t in tools.tools]}")
            
            # è°ƒç”¨è·¯å¾„è§„åˆ’å·¥å…·
            result = await session.call_tool(
                "route_planning",
                arguments={
                    "origin": "116.481028,39.989643",  # èµ·ç‚¹ç»çº¬åº¦
                    "destination": "116.434446,39.90816",  # ç»ˆç‚¹ç»çº¬åº¦
                    "mode": "transit"  # å…¬å…±äº¤é€š
                }
            )
            
            return result

# åœ¨æ™ºèƒ½ä½“çš„æ„ŸçŸ¥èŠ‚ç‚¹ä¸­è°ƒç”¨ï¼š
# traffic_info = await call_amap_mcp()
'''
    
    print(mcp_example_code)
    print("\nä¸Šè¿°ä»£ç å±•ç¤ºäº† MCP Client çš„å…¸å‹ç”¨æ³•ã€‚")
    print("å®é™…éƒ¨ç½²æ—¶ï¼Œéœ€è¦å°†æ­¤é€»è¾‘é›†æˆåˆ° LangGraph çš„æ„ŸçŸ¥èŠ‚ç‚¹ä¸­ã€‚\n")


# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šFastAPI æ¥å£ç¤ºä¾‹
# ============================================================

def print_fastapi_example():
    """
    å±•ç¤ºå¦‚ä½•å°†æ™ºèƒ½ä½“å°è£…ä¸º FastAPI æœåŠ¡ã€‚
    """
    print("\n" + "="*60)
    print("FastAPI æ¥å£ç¤ºä¾‹ä»£ç ")
    print("="*60)
    
    fastapi_code = '''
# FastAPI æ¥å£å°è£…ç¤ºä¾‹

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

app = FastAPI(
    title="äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ API",
    description="åŸºäº LangGraph + CDHGNN çš„æ™ºèƒ½å‡ºè¡Œæ¨èæœåŠ¡",
    version="1.0.0"
)

class TravelRequest(BaseModel):
    """å‡ºè¡Œè¯·æ±‚æ¨¡å‹"""
    origin: str          # èµ·ç‚¹
    destination: str     # ç»ˆç‚¹
    user_request: str    # ç”¨æˆ·è‡ªç„¶è¯­è¨€æè¿°

class TravelRecommendation(BaseModel):
    """å‡ºè¡Œæ¨èå“åº”"""
    recommendation: str
    candidate_plans: list
    reflection_score: float

@app.post("/recommend", response_model=TravelRecommendation)
async def get_travel_recommendation(request: TravelRequest):
    """
    è·å–å‡ºè¡Œæ¨è
    
    è°ƒç”¨äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ï¼Œè¿”å›ä¸ªæ€§åŒ–çš„å‡ºè¡Œå»ºè®®ã€‚
    """
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = create_traffic_guidance_agent()
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "user_request": request.user_request,
        "origin": request.origin,
        "destination": request.destination,
        "traffic_status": "",
        "candidate_plans": [],
        "recommendation": "",
        "reflection_score": 0.0,
        "messages": [],
        "current_step": "init"
    }
    
    # è¿è¡Œæ™ºèƒ½ä½“
    final_state = agent.invoke(initial_state)
    
    return TravelRecommendation(
        recommendation=final_state["recommendation"],
        candidate_plans=final_state["candidate_plans"],
        reflection_score=final_state["reflection_score"]
    )

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"status": "healthy"}

# å¯åŠ¨æœåŠ¡ï¼š
# uvicorn smoke_test:app --host 0.0.0.0 --port 8000
'''
    
    print(fastapi_code)
    print("\nå°†ä¸Šè¿°ä»£ç æ·»åŠ åˆ°æœ¬æ–‡ä»¶ï¼Œå³å¯å¯åŠ¨ FastAPI æœåŠ¡ã€‚")
    print("è®¿é—® http://localhost:8000/docs æŸ¥çœ‹ Swagger UIã€‚\n")


# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šä¸»å‡½æ•° - è¿è¡Œ Smoke Test
# ============================================================

async def main():
    """
    Smoke Test ä¸»å‡½æ•°
    """
    print("="*60)
    print("ğŸš— äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ Smoke Test")
    print("="*60)
    
    # 1. åˆ›å»ºæ™ºèƒ½ä½“
    print("\nğŸ“¦ æ­£åœ¨åˆ›å»º LangGraph æ™ºèƒ½ä½“...")
    agent = create_traffic_guidance_agent()
    print("âœ… æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸï¼")
    
    # 2. å‡†å¤‡æµ‹è¯•ç”¨ä¾‹
    test_case = {
        "user_request": "æˆ‘éœ€è¦ä»åŒ—äº¬è¥¿ç«™å»ä¸­å…³æ‘ï¼Œç°åœ¨æ˜¯æ—©é«˜å³°ï¼Œè¯·æ¨èæœ€å¿«çš„æ–¹å¼",
        "origin": "åŒ—äº¬è¥¿ç«™",
        "destination": "ä¸­å…³æ‘",
        "traffic_status": "",
        "candidate_plans": [],
        "recommendation": "",
        "reflection_score": 0.0,
        "messages": [],
        "current_step": "init"
    }
    
    print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ï¼š")
    print(f"   èµ·ç‚¹ï¼š{test_case['origin']}")
    print(f"   ç»ˆç‚¹ï¼š{test_case['destination']}")
    print(f"   ç”¨æˆ·éœ€æ±‚ï¼š{test_case['user_request']}")
    
    # 3. è¿è¡Œæ™ºèƒ½ä½“
    print("\n" + "-"*60)
    print("ğŸš€ å¼€å§‹è¿è¡Œæ™ºèƒ½ä½“...")
    print("-"*60)
    
    try:
        # æ£€æŸ¥ API Key
        if OPENAI_API_KEY == "your-api-key-here":
            print("\nâš ï¸  è­¦å‘Šï¼šæœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡åé‡æ–°è¿è¡Œï¼š")
            print("   $env:OPENAI_API_KEY = 'your-actual-api-key'")
            print("\n   ä¸‹é¢å°†å±•ç¤º MCP å’Œ FastAPI çš„ç¤ºä¾‹ä»£ç ...\n")
        else:
            # å®é™…è¿è¡Œæ™ºèƒ½ä½“
            final_state = agent.invoke(test_case)
            
            print("\n" + "-"*60)
            print("ğŸ“Š è¿è¡Œç»“æœ")
            print("-"*60)
            print(f"\nğŸ¯ æ¨èç»“æœï¼š{final_state['recommendation']}")
            print(f"\nğŸ“‹ å€™é€‰æ–¹æ¡ˆï¼š")
            for i, plan in enumerate(final_state["candidate_plans"], 1):
                print(f"   æ–¹æ¡ˆ {i}: {plan}")
            print(f"\nâœ… åæ€è¯„åˆ†ï¼š{final_state['reflection_score']:.2f}")
    
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™ï¼š{e}")
        print("   è¯·æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®é…ç½®ã€‚")
    
    # 4. å±•ç¤º MCP ç¤ºä¾‹
    await demo_mcp_client()
    
    # 5. å±•ç¤º FastAPI ç¤ºä¾‹
    print_fastapi_example()
    
    # 6. æ€»ç»“
    print("="*60)
    print("ğŸ‰ Smoke Test å®Œæˆï¼")
    print("="*60)
    print("""
æœ¬ Demo å±•ç¤ºäº†ä»¥ä¸‹æŠ€æœ¯è¦ç‚¹ï¼š

1. LangGraph æœ‰å‘å¾ªç¯å›¾ï¼ˆDCGï¼‰ç»“æ„
   - æ„ŸçŸ¥èŠ‚ç‚¹ â†’ è§„åˆ’èŠ‚ç‚¹ â†’ åæ€èŠ‚ç‚¹ â†’ (å¾ªç¯æˆ–è¾“å‡º)
   - çŠ¶æ€ç®¡ç†ä¸æ¡ä»¶è¾¹å®ç°

2. MCP (Model Context Protocol) é›†æˆ
   - è¿æ¥é«˜å¾·åœ°å›¾ MCP Server
   - æ ‡å‡†åŒ–å·¥å…·è°ƒç”¨æ¥å£

3. FastAPI æœåŠ¡å°è£…
   - RESTful API è®¾è®¡
   - Pydantic æ•°æ®éªŒè¯

ä¸‹ä¸€æ­¥ï¼š
- é…ç½®çœŸå®çš„ API Key
- éƒ¨ç½²é«˜å¾·åœ°å›¾ MCP Server
- å°†æœ¬ Demo æ‰©å±•ä¸ºå®Œæ•´çš„å‡ºè¡Œæ¨èç³»ç»Ÿ
""")


if __name__ == "__main__":
    asyncio.run(main())
