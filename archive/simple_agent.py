"""
äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ - ç®€å•ç‰ˆæœ¬ (å¸¦ Gradio å¯¹è¯ç•Œé¢)
=================================================

ğŸ¯ ç›®æ ‡ï¼šå¿«é€Ÿè·‘é€šæµç¨‹ï¼Œæˆªå›¾æ”¾è®ºæ–‡

è¿è¡Œæ–¹å¼ï¼š
    python simple_agent.py

ç„¶åæ‰“å¼€æµè§ˆå™¨è®¿é—® http://localhost:7860
"""

import os
import json
import gradio as gr
from openai import OpenAI

# ============================================================
# é…ç½®
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-0d450dd391d3431d895d24dbde5d7a46")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "http://127.0.0.1:8045/v1")
MODEL_NAME = os.getenv("MODEL_NAME", "gemini-3-flash")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(
    base_url=OPENAI_BASE_URL,
    api_key=OPENAI_API_KEY
) if OPENAI_API_KEY else None

# ============================================================
# æ¨¡æ‹Ÿçš„"å·¥å…·"ï¼ˆä½ è®ºæ–‡ä¸­çš„æ¨¡å‹ï¼‰
# ============================================================

def tool_traffic_prediction(origin: str, destination: str, time: str) -> dict:
    """
    ğŸ”§ å·¥å…·1ï¼šæ—¶ç©ºé¢„æµ‹æ¨¡å‹ï¼ˆç¬¬ä¸€ç« ï¼‰
    æ¨¡æ‹Ÿè°ƒç”¨ä½ è®ºæ–‡ç¬¬ä¸€ç« çš„ Transformer æ—¶ç©ºé¢„æµ‹æ¨¡å‹
    """
    return {
        "tool": "æ—¶ç©ºé¢„æµ‹æ¨¡å‹",
        "source": "ç¬¬ä¸€ç« ï¼šåŸºäºTransformerçš„è·¯ç½‘æ—¶ç©ºé¢„è®­ç»ƒ",
        "result": {
            "æ‹¥å µæŒ‡æ•°": 0.72,
            "é¢„æµ‹é€Ÿåº¦": "35 km/h",
            "ç½®ä¿¡åº¦": 0.89,
            "å¤‡æ³¨": f"é¢„æµ‹ {time} ä» {origin} åˆ° {destination} çš„äº¤é€šçŠ¶æ€"
        }
    }

def tool_anomaly_detection(location: str) -> dict:
    """
    ğŸ”§ å·¥å…·2ï¼šå¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹ï¼ˆç¬¬äºŒç« ï¼‰
    æ¨¡æ‹Ÿè°ƒç”¨ä½ è®ºæ–‡ç¬¬äºŒç« çš„å¤šæ¨¡æ€å¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹
    """
    # æ¨¡æ‹Ÿä¸€äº›å¼‚å¸¸åœºæ™¯
    anomalies = [
        {"ç±»å‹": "äº¤é€šäº‹æ•…", "ä½ç½®": "ä¸œä¸‰ç¯", "å½±å“æ—¶é•¿": "çº¦2å°æ—¶", "ä¸¥é‡ç¨‹åº¦": "ä¸­ç­‰"},
        {"ç±»å‹": "é“è·¯æ–½å·¥", "ä½ç½®": "è¥¿ç›´é—¨æ¡¥", "å½±å“æ—¶é•¿": "æŒç»­è‡³æœ¬å‘¨äº”", "ä¸¥é‡ç¨‹åº¦": "è½»å¾®"},
        {"ç±»å‹": "æ— å¼‚å¸¸", "ä½ç½®": location, "å½±å“æ—¶é•¿": "-", "ä¸¥é‡ç¨‹åº¦": "-"}
    ]
    import random
    result = random.choice(anomalies)
    
    return {
        "tool": "å¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹",
        "source": "ç¬¬äºŒç« ï¼šèåˆLLMçš„å¤šæ¨¡æ€å¼‚å¸¸æ„ŸçŸ¥",
        "result": result
    }

def tool_causal_analysis(affected_area: str) -> dict:
    """
    ğŸ”§ å·¥å…·3ï¼šå› æœåˆ†ææ¨¡å‹ï¼ˆç¬¬ä¸‰ç« ï¼‰
    æ¨¡æ‹Ÿè°ƒç”¨ä½ è®ºæ–‡ç¬¬ä¸‰ç« çš„ GeoDCD å› æœå‘ç°æ¡†æ¶
    """
    return {
        "tool": "å› æœåˆ†ææ¨¡å‹",
        "source": "ç¬¬ä¸‰ç« ï¼šåŸºäºå‡ ä½•æ·±åº¦å­¦ä¹ çš„åŠ¨æ€å› æœå‘ç°",
        "result": {
            "å½±å“ä¼ æ’­è·¯å¾„": f"{affected_area} â†’ äºŒç¯è¾…è·¯ â†’ è¥¿ç›´é—¨",
            "é¢„è®¡æ³¢åŠæ—¶é—´": "30-45åˆ†é’Ÿ",
            "å› æœå¼ºåº¦": 0.78,
            "å»ºè®®ç»•è¡Œ": "åŒ—ä¸‰ç¯æˆ–å››ç¯"
        }
    }

def tool_travel_recommendation(user_id: str, origin: str, destination: str) -> dict:
    """
    ğŸ”§ å·¥å…·4ï¼šå‡ºè¡Œæ¨èæ¨¡å‹ CDHGNNï¼ˆç¬¬å››ç« ï¼‰
    æ¨¡æ‹Ÿè°ƒç”¨ä½ è®ºæ–‡ç¬¬å››ç« çš„å¯¹æ¯”å»åå¼‚æ„å›¾ç¥ç»ç½‘ç»œ
    """
    recommendations = [
        {"æ–¹å¼": "åœ°é“", "æ—¶é—´": "35åˆ†é’Ÿ", "è´¹ç”¨": "5å…ƒ", "æ¨èæŒ‡æ•°": 0.92},
        {"æ–¹å¼": "å…¬äº¤+åœ°é“", "æ—¶é—´": "45åˆ†é’Ÿ", "è´¹ç”¨": "4å…ƒ", "æ¨èæŒ‡æ•°": 0.78},
        {"æ–¹å¼": "æ‰“è½¦", "æ—¶é—´": "40åˆ†é’Ÿ", "è´¹ç”¨": "55å…ƒ", "æ¨èæŒ‡æ•°": 0.65},
    ]
    
    return {
        "tool": "CDHGNNæ¨èæ¨¡å‹",
        "source": "ç¬¬å››ç« ï¼šå¯¹æ¯”å»åå¼‚æ„å›¾ç¥ç»ç½‘ç»œ",
        "result": {
            "ç”¨æˆ·ç”»åƒ": f"ç”¨æˆ· {user_id}ï¼Œé€šå‹¤æ—ï¼Œåå¥½å¿«é€Ÿåˆ°è¾¾",
            "æ¨èæ–¹æ¡ˆ": recommendations,
            "å»åç½®ä¿¡åº¦": 0.87
        }
    }

def tool_route_planning(origin: str, destination: str, mode: str) -> dict:
    """
    ğŸ”§ å·¥å…·5ï¼šé«˜å¾·åœ°å›¾è·¯å¾„è§„åˆ’ï¼ˆMCP å¤–éƒ¨å·¥å…·ï¼‰
    æ¨¡æ‹Ÿ MCP è°ƒç”¨é«˜å¾·åœ°å›¾ API
    """
    routes = {
        "åœ°é“": {"è·¯çº¿": "9å·çº¿ â†’ 10å·çº¿ â†’ çŸ¥æ˜¥è·¯ç«™", "è·ç¦»": "12.5km", "æ¢ä¹˜": "1æ¬¡"},
        "å…¬äº¤": {"è·¯çº¿": "387è·¯ â†’ åœ°é“4å·çº¿", "è·ç¦»": "14.2km", "æ¢ä¹˜": "1æ¬¡"},
        "é©¾è½¦": {"è·¯çº¿": "è²èŠ±æ± ä¸œè·¯ â†’ è¥¿äºŒç¯ â†’ åŒ—ä¸‰ç¯", "è·ç¦»": "15.8km", "æ”¶è´¹": "æ— "},
    }
    
    return {
        "tool": "é«˜å¾·åœ°å›¾MCP",
        "source": "å¤–éƒ¨èƒ½åŠ›ï¼šMCPåè®®è°ƒç”¨",
        "result": routes.get(mode, routes["åœ°é“"])
    }

# ============================================================
# å·¥å…·æ³¨å†Œè¡¨ï¼ˆå‘Šè¯‰ LLM æœ‰å“ªäº›å·¥å…·å¯ç”¨ï¼‰
# ============================================================

TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "traffic_prediction",
            "description": "è°ƒç”¨ç¬¬ä¸€ç« çš„æ—¶ç©ºé¢„æµ‹æ¨¡å‹ï¼Œé¢„æµ‹æŒ‡å®šè·¯æ®µçš„äº¤é€šçŠ¶æ€",
            "parameters": {
                "type": "object",
                "properties": {
                    "origin": {"type": "string", "description": "èµ·ç‚¹ä½ç½®"},
                    "destination": {"type": "string", "description": "ç»ˆç‚¹ä½ç½®"},
                    "time": {"type": "string", "description": "é¢„æµ‹æ—¶é—´"}
                },
                "required": ["origin", "destination", "time"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "anomaly_detection",
            "description": "è°ƒç”¨ç¬¬äºŒç« çš„å¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹ï¼Œæ£€æµ‹æŒ‡å®šåŒºåŸŸçš„äº¤é€šå¼‚å¸¸äº‹ä»¶",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "æ£€æµ‹åŒºåŸŸ"}
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "causal_analysis",
            "description": "è°ƒç”¨ç¬¬ä¸‰ç« çš„å› æœåˆ†ææ¨¡å‹ï¼Œåˆ†æå¼‚å¸¸äº‹ä»¶çš„ä¼ æ’­å½±å“",
            "parameters": {
                "type": "object",
                "properties": {
                    "affected_area": {"type": "string", "description": "å—å½±å“åŒºåŸŸ"}
                },
                "required": ["affected_area"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "travel_recommendation",
            "description": "è°ƒç”¨ç¬¬å››ç« çš„CDHGNNæ¨¡å‹ï¼Œä¸ºç”¨æˆ·æ¨èæœ€ä¼˜å‡ºè¡Œæ–¹å¼",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {"type": "string", "description": "ç”¨æˆ·ID"},
                    "origin": {"type": "string", "description": "èµ·ç‚¹"},
                    "destination": {"type": "string", "description": "ç»ˆç‚¹"}
                },
                "required": ["origin", "destination"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "route_planning",
            "description": "é€šè¿‡MCPåè®®è°ƒç”¨é«˜å¾·åœ°å›¾ï¼Œè·å–è¯¦ç»†è·¯çº¿è§„åˆ’",
            "parameters": {
                "type": "object",
                "properties": {
                    "origin": {"type": "string", "description": "èµ·ç‚¹"},
                    "destination": {"type": "string", "description": "ç»ˆç‚¹"},
                    "mode": {"type": "string", "description": "äº¤é€šæ–¹å¼ï¼šåœ°é“/å…¬äº¤/é©¾è½¦"}
                },
                "required": ["origin", "destination", "mode"]
            }
        }
    }
]

# å·¥å…·æ‰§è¡Œå‡½æ•°æ˜ å°„
TOOL_FUNCTIONS = {
    "traffic_prediction": lambda args: tool_traffic_prediction(args.get("origin", "æœªçŸ¥èµ·ç‚¹"), args.get("destination", "æœªçŸ¥ç»ˆç‚¹"), args.get("time", "å½“å‰")),
    "anomaly_detection": lambda args: tool_anomaly_detection(args.get("location", "æœªçŸ¥åŒºåŸŸ")),
    "causal_analysis": lambda args: tool_causal_analysis(args.get("affected_area", "æœªçŸ¥åŒºåŸŸ")),
    "travel_recommendation": lambda args: tool_travel_recommendation(args.get("user_id", "U001"), args.get("origin", "æœªçŸ¥èµ·ç‚¹"), args.get("destination", "æœªçŸ¥ç»ˆç‚¹")),
    "route_planning": lambda args: tool_route_planning(args.get("origin", "æœªçŸ¥èµ·ç‚¹"), args.get("destination", "æœªçŸ¥ç»ˆç‚¹"), args.get("mode", "åœ°é“")),
}

# ============================================================
# æ™ºèƒ½ä½“æ ¸å¿ƒé€»è¾‘
# ============================================================

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½äº¤é€šè¯±å¯¼åŠ©æ‰‹ï¼ŒåŸºäºåšå£«è®ºæ–‡ã€Šé¢å‘å¼‚å¸¸æ€åŠ¿çš„è¶…å¤§è§„æ¨¡è·¯ç½‘äº¤é€šé¢„æµ‹ä¸è¯±å¯¼ã€‹ä¸­çš„ç ”ç©¶æˆæœæ„å»ºã€‚

ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š
1. **æ—¶ç©ºé¢„æµ‹æ¨¡å‹**ï¼ˆç¬¬ä¸€ç« ï¼‰ï¼šé¢„æµ‹è·¯ç½‘äº¤é€šçŠ¶æ€
2. **å¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹**ï¼ˆç¬¬äºŒç« ï¼‰ï¼šæ£€æµ‹äº¤é€šå¼‚å¸¸äº‹ä»¶
3. **å› æœåˆ†ææ¨¡å‹**ï¼ˆç¬¬ä¸‰ç« ï¼‰ï¼šåˆ†æå¼‚å¸¸ä¼ æ’­å½±å“
4. **CDHGNNæ¨èæ¨¡å‹**ï¼ˆç¬¬å››ç« ï¼‰ï¼šæ¨èæœ€ä¼˜å‡ºè¡Œæ–¹å¼
5. **é«˜å¾·åœ°å›¾MCP**ï¼šè·å–è¯¦ç»†è·¯çº¿è§„åˆ’

å·¥ä½œæµç¨‹ï¼š
1. ç†è§£ç”¨æˆ·çš„å‡ºè¡Œéœ€æ±‚
2. æ ¹æ®éœ€æ±‚è°ƒç”¨åˆé€‚çš„å·¥å…·ï¼ˆå¯ä»¥è°ƒç”¨å¤šä¸ªï¼‰
3. ç»¼åˆå·¥å…·è¿”å›çš„ç»“æœ
4. ç”Ÿæˆå‹å¥½ã€å¯æ“ä½œçš„å‡ºè¡Œå»ºè®®æŠ¥å‘Š


è¯·ç”¨ä¸“ä¸šä½†å‹å¥½çš„è¯­æ°”å›å¤ï¼Œé€‚å½“ä½¿ç”¨ emoji è®©å›å¤æ›´ç”ŸåŠ¨ã€‚

âš ï¸ é‡è¦æç¤ºï¼š
å¦‚æœéœ€è¦è°ƒç”¨å¤šä¸ªå·¥å…·ï¼Œè¯·åŠ¡å¿…ç”Ÿæˆå¤šä¸ªç‹¬ç«‹çš„å·¥å…·è°ƒç”¨ï¼ˆTool Callsï¼‰ï¼Œç»ä¸è¦åœ¨ä¸€ä¸ªå·¥å…·è°ƒç”¨çš„å‚æ•°ä¸­æ‹¼æ¥å¤šä¸ª JSON å¯¹è±¡ï¼
æ¯ä¸ªå·¥å…·è°ƒç”¨åªéœ€åŒ…å«è¯¥å·¥å…·æ‰€éœ€çš„å‚æ•°ã€‚"""


def run_agent(user_message: str, history: list) -> str:
    """
    è¿è¡Œæ™ºèƒ½ä½“ï¼šç†è§£ç”¨æˆ·æ„å›¾ â†’ è°ƒç”¨å·¥å…· â†’ ç”ŸæˆæŠ¥å‘Š
    """
    if not client:
        return "âš ï¸ è¯·å…ˆè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼\n\nè®¾ç½®æ–¹æ³•ï¼š\n```powershell\n$env:OPENAI_API_KEY = 'sk-xxxxxxxx'\n```"
    
    # æ„å»ºæ¶ˆæ¯å†å²
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    for h in history:
        messages.append({"role": "user", "content": h[0]})
        messages.append({"role": "assistant", "content": h[1]})
    messages.append({"role": "user", "content": user_message})
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šè®© LLM å†³å®šè°ƒç”¨å“ªäº›å·¥å…·
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            tools=TOOLS,
            tool_choice="auto"
        )
        assistant_message = response.choices[0].message
    except Exception as e:
        error_msg = f"âš ï¸ API è°ƒç”¨å¤±è´¥ï¼š{str(e)}"
        print(f"\nâŒ [ERROR] {error_msg}\n")
        return error_msg
    
    # ====== DEBUG: æ‰“å°LLMåŸå§‹è¾“å‡º ======
    print("\n" + "="*60)
    print("ğŸ” [DEBUG] LLM åŸå§‹è¾“å‡º:")
    print("="*60)
    print(f"Content: {assistant_message.content}")
    if assistant_message.tool_calls:
        print(f"\nTool Calls ({len(assistant_message.tool_calls)}ä¸ª):")
        for i, tc in enumerate(assistant_message.tool_calls):
            print(f"  [{i+1}] {tc.function.name}")
            print(f"      Arguments: {tc.function.arguments}")
    else:
        print("\nTool Calls: æ— ")
    print("="*60 + "\n")
    
    # å¦‚æœ LLM å†³å®šè°ƒç”¨å·¥å…·
    tool_results = []
    if assistant_message.tool_calls:
        for tool_call in assistant_message.tool_calls:
            func_name = tool_call.function.name
            args_str = tool_call.function.arguments
            
            # æ£€æµ‹æ˜¯å¦æœ‰å¤šä¸ªJSONå¯¹è±¡è¢«æ‹¼æ¥ï¼ˆLLMæ ¼å¼é”™è¯¯ï¼‰
            # ä¾‹å¦‚: {"a":1}{"b":2} åº”è¯¥è¢«æ‹†åˆ†
            # import re
            # json_objects = re.findall(r'\{[^{}]*\}', args_str)
            
            # ä½¿ç”¨æ›´å¥å£®çš„æ‹¬å·è®¡æ•°æ³•æå– JSON
            json_objects = []
            stack = 0
            start_index = -1
            for i, char in enumerate(args_str):
                if char == '{':
                    if stack == 0:
                        start_index = i
                    stack += 1
                elif char == '}':
                    stack -= 1
                    if stack == 0 and start_index != -1:
                        json_objects.append(args_str[start_index:i+1])
                        start_index = -1
            
            if len(json_objects) > 1:
                print(f"âš ï¸ [DEBUG] æ£€æµ‹åˆ°å¤šä¸ªJSONå¯¹è±¡è¢«æ‹¼æ¥ï¼Œå°è¯•åŒ¹é…æ­£ç¡®çš„å‚æ•°...")
                print(f"   æ‰¾åˆ° {len(json_objects)} ä¸ªJSONå¯¹è±¡: {json_objects}")
            
            try:
                func_args = json.loads(args_str)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ [DEBUG] JSONè§£æå¤±è´¥: {e}")
                print(f"   åŸå§‹å­—ç¬¦ä¸²: {args_str}")
                
                # æ ¹æ®å·¥å…·ç±»å‹é€‰æ‹©åˆé€‚çš„JSONå¯¹è±¡
                func_args = None
                for json_str in json_objects:
                    try:
                        candidate = json.loads(json_str)
                        # æ£€æŸ¥è¿™ä¸ªå€™é€‰å¯¹è±¡æ˜¯å¦åŒ…å«å½“å‰å·¥å…·æ‰€éœ€çš„å‚æ•°
                        if func_name == "travel_recommendation" and ("origin" in candidate or "destination" in candidate):
                            func_args = candidate
                            print(f"   âœ“ ä¸º {func_name} åŒ¹é…åˆ°: {func_args}")
                            break
                        elif func_name == "anomaly_detection" and "location" in candidate:
                            func_args = candidate
                            print(f"   âœ“ ä¸º {func_name} åŒ¹é…åˆ°: {func_args}")
                            break
                        elif func_name == "traffic_prediction" and "origin" in candidate and "destination" in candidate:
                            func_args = candidate
                            print(f"   âœ“ ä¸º {func_name} åŒ¹é…åˆ°: {func_args}")
                            break
                        elif func_name == "causal_analysis" and "affected_area" in candidate:
                            func_args = candidate
                            print(f"   âœ“ ä¸º {func_name} åŒ¹é…åˆ°: {func_args}")
                            break
                        elif func_name == "route_planning" and "mode" in candidate:
                            func_args = candidate
                            print(f"   âœ“ ä¸º {func_name} åŒ¹é…åˆ°: {func_args}")
                            break
                    except:
                        continue
                
                if func_args is None and json_objects:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
                    try:
                        func_args = json.loads(json_objects[0])
                        print(f"   âš ï¸ æœªèƒ½ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªJSON: {func_args}")
                    except:
                        print(f"   âŒ æ— æ³•è§£æä»»ä½•JSONå¯¹è±¡")
                        continue
                elif func_args is None:
                    print(f"   âŒ æ— å¯ç”¨çš„JSONå¯¹è±¡")
                    continue
            
            # æ‰§è¡Œå·¥å…·
            if func_name in TOOL_FUNCTIONS:
                result = TOOL_FUNCTIONS[func_name](func_args)
                tool_results.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": func_name,
                    "content": json.dumps(result, ensure_ascii=False)
                })
        
        # å°†å·¥å…·ç»“æœå‘å› LLMï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        messages.append(assistant_message)
        messages.extend(tool_results)
        
        try:
            final_response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages
            )
            
            # DEBUG: æ‰“å°æœ€ç»ˆå“åº”è¯¦æƒ…
            print("-"*60)
            print("ğŸ” [DEBUG] æœ€ç»ˆå“åº”:")
            print(f"Content: {final_response.choices[0].message.content}")
            print(f"Finish Reason: {final_response.choices[0].finish_reason}")
            print("-" * 60)
            
            result = final_response.choices[0].message.content
            if not result:
                return "âš ï¸ LLM è¿”å›äº†ç©ºå†…å®¹ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å°è¯•ç»§ç»­è°ƒç”¨å·¥å…·ï¼Œä½†ç¬¬äºŒè½®å¹¶æœªæä¾›å·¥å…·å®šä¹‰ã€‚è¯·é‡è¯•ã€‚"
            return result
        except Exception as e:
            error_msg = f"âš ï¸ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šæ—¶ API è°ƒç”¨å¤±è´¥ï¼š{str(e)}"
            print(f"\nâŒ [ERROR] {error_msg}\n")
            return error_msg
    
    # å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¿”å›
    result = assistant_message.content
    return result if result else "ğŸ¤” æˆ‘ä¸å¤ªç¡®å®šå¦‚ä½•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·æ¢ä¸ªæ–¹å¼æé—®è¯•è¯•ã€‚"


# ============================================================
# Gradio å¯¹è¯ç•Œé¢
# ============================================================

def create_ui():
    """åˆ›å»º Gradio å¯¹è¯ç•Œé¢"""
    
    with gr.Blocks(
        title="ğŸš— æ™ºèƒ½äº¤é€šè¯±å¯¼åŠ©æ‰‹",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="slate",
        ),
        css="""
        .gradio-container { max-width: 900px !important; }
        .message { font-size: 15px !important; }
        footer { display: none !important; }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸš— æ™ºèƒ½äº¤é€šè¯±å¯¼åŠ©æ‰‹
        
        > åŸºäºåšå£«è®ºæ–‡ã€Šé¢å‘å¼‚å¸¸æ€åŠ¿çš„è¶…å¤§è§„æ¨¡è·¯ç½‘äº¤é€šé¢„æµ‹ä¸è¯±å¯¼ã€‹ç ”ç©¶æˆæœ
        
        **å¯ç”¨èƒ½åŠ›ï¼š**
        - ğŸ“Š æ—¶ç©ºé¢„æµ‹æ¨¡å‹ï¼ˆç¬¬ä¸€ç« ï¼‰
        - âš ï¸ å¼‚å¸¸æ„ŸçŸ¥æ¨¡å‹ï¼ˆç¬¬äºŒç« ï¼‰
        - ğŸ”— å› æœåˆ†ææ¨¡å‹ï¼ˆç¬¬ä¸‰ç« ï¼‰
        - ğŸ¯ CDHGNNæ¨èæ¨¡å‹ï¼ˆç¬¬å››ç« ï¼‰
        - ğŸ—ºï¸ é«˜å¾·åœ°å›¾MCP
        
        ---
        """)
        
        chatbot = gr.Chatbot(
            label="å¯¹è¯è®°å½•",
            height=450,
            show_label=False,
            avatar_images=(None, "https://api.dicebear.com/7.x/bottts/svg?seed=agent"),
        )
        
        with gr.Row():
            msg = gr.Textbox(
                label="è¾“å…¥æ‚¨çš„å‡ºè¡Œéœ€æ±‚",
                placeholder="ä¾‹å¦‚ï¼šæˆ‘æ˜å¤©æ—©ä¸Š8ç‚¹è¦ä»åŒ—äº¬è¥¿ç«™å»ä¸­å…³æ‘ï¼Œå¬è¯´ä¸‰ç¯æœ‰æ–½å·¥ï¼Œå¸®æˆ‘è§„åˆ’ä¸€ä¸‹",
                scale=4,
                show_label=False,
            )
            submit = gr.Button("å‘é€ ğŸš€", variant="primary", scale=1)
        
        with gr.Row():
            gr.Examples(
                examples=[
                    "æˆ‘æƒ³ä»åŒ—äº¬è¥¿ç«™å»ä¸­å…³æ‘ï¼Œç°åœ¨æ˜¯æ—©é«˜å³°ï¼Œæ¨èæ€ä¹ˆèµ°ï¼Ÿ",
                    "å¸®æˆ‘æŸ¥ä¸€ä¸‹ä¸œä¸‰ç¯ç›®å‰æœ‰æ²¡æœ‰äº¤é€šå¼‚å¸¸ï¼Ÿ",
                    "å¦‚æœè¥¿äºŒç¯å‘ç”Ÿäº‹æ•…ï¼Œä¼šå½±å“åˆ°å“ªäº›è·¯æ®µï¼Ÿ",
                    "é¢„æµ‹æ˜å¤©ä¸‹åˆ5ç‚¹åŒ—äº¬å—ç«™åˆ°æœ›äº¬çš„äº¤é€šçŠ¶å†µ",
                ],
                inputs=msg,
                label="ğŸ’¡ ç¤ºä¾‹é—®é¢˜"
            )
        
        def respond(message, chat_history):
            if not message.strip():
                return "", chat_history
            
            # å°†æ–°æ ¼å¼è½¬æ¢ä¸ºæ—§æ ¼å¼ä¾› run_agent ä½¿ç”¨
            old_format_history = []
            for item in chat_history:
                if isinstance(item, dict):
                    # æ–°æ ¼å¼: {"role": "user/assistant", "content": "..."}
                    if item.get("role") == "user":
                        old_format_history.append((item.get("content", ""), ""))
                    elif item.get("role") == "assistant" and old_format_history:
                        last = old_format_history[-1]
                        old_format_history[-1] = (last[0], item.get("content", ""))
                elif isinstance(item, tuple):
                    old_format_history.append(item)
            
            # è¿è¡Œæ™ºèƒ½ä½“
            bot_response = run_agent(message, old_format_history)
            
            # ä½¿ç”¨æ–°æ ¼å¼æ·»åŠ æ¶ˆæ¯
            chat_history.append({"role": "user", "content": message})
            chat_history.append({"role": "assistant", "content": bot_response})
            return "", chat_history
        
        # ç»‘å®šäº‹ä»¶
        submit.click(respond, [msg, chatbot], [msg, chatbot])
        msg.submit(respond, [msg, chatbot], [msg, chatbot])
        
        gr.Markdown("""
        ---
        <center>
        
        **æŠ€æœ¯æ¶æ„ï¼š** LangGraph è®¤çŸ¥ç¼–æ’ + OpenAI GPT + MCP åè®® + FastAPI
        
        *æœ¬ç³»ç»Ÿä¸ºåšå£«è®ºæ–‡ç¬¬å››ç« æŠ€æœ¯æ¼”ç¤º*
        
        </center>
        """)
    
    return demo


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

if __name__ == "__main__":
    print("="*60)
    print("ğŸš— æ™ºèƒ½äº¤é€šè¯±å¯¼åŠ©æ‰‹")
    print("="*60)
    
    if not OPENAI_API_KEY:
        print("\nâš ï¸  è­¦å‘Šï¼šæœªæ£€æµ‹åˆ° OPENAI_API_KEY")
        print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print("   $env:OPENAI_API_KEY = 'sk-xxxxxxxx'")
        print("\n   ç•Œé¢ä»ä¼šå¯åŠ¨ï¼Œä½†æ— æ³•è¿›è¡ŒçœŸå®å¯¹è¯ã€‚\n")
    else:
        print(f"\nâœ… å·²æ£€æµ‹åˆ° API Keyï¼ˆä»¥ {OPENAI_API_KEY[:8]}... å¼€å¤´ï¼‰\n")
    
    print("ğŸŒ æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...")
    print("   è®¿é—®åœ°å€ï¼šhttp://localhost:7860")
    print("   æŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")
    
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # è®¾ä¸º True å¯ç”Ÿæˆå…¬ç½‘é“¾æ¥
        show_error=True
    )
