import json
import time
import re
from typing import Literal, Optional
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage, ToolMessage, BaseMessage
from ..core.state import AgentState
from ..core.llm import get_llm
from ..tools.traffic_tools import traffic_prediction, anomaly_detection, causal_analysis, travel_recommendation
from ..tools.maps import route_planning

# è·å– LLM å®ä¾‹ (ä¸å† bind_tools)
llm = get_llm()

# å·¥å…·æ˜ å°„è¡¨
TOOL_MAP = {
    "traffic_prediction": traffic_prediction,
    "anomaly_detection": anomaly_detection,
    "causal_analysis": causal_analysis,
    "travel_recommendation": travel_recommendation,
    "route_planning": route_planning
}

# æ‰‹åŠ¨ç”Ÿæˆå·¥å…·æè¿°æ–‡æ¡£
TOOL_DESC = """
1. route_planning: è·¯å¾„è§„åˆ’ã€‚å‚æ•°: origin(èµ·ç‚¹), destination(ç»ˆç‚¹), mode(transit/driving/walking)ã€‚
2. traffic_prediction: é¢„æµ‹äº¤é€šæ‹¥å µã€‚å‚æ•°: origin, destinationã€‚
3. anomaly_detection: æ£€æµ‹å¼‚å¸¸äº‹ä»¶ã€‚å‚æ•°: locationã€‚
4. causal_analysis: åˆ†æäº‹æ•…å½±å“ã€‚å‚æ•°: affected_areaã€‚
5. travel_recommendation: ç»¼åˆå‡ºè¡Œæ¨èã€‚å‚æ•°: origin, destinationã€‚
"""

# æœ€å¤§é‡è¯•æ¬¡æ•°
MAX_RETRY_COUNT = 3

# --- Debug è¾…åŠ©å‡½æ•° ---
def _add_debug_log(state: AgentState, log_type: str, content: dict) -> None:
    if "debug_logs" not in state or state["debug_logs"] is None:
        state["debug_logs"] = []
    state["debug_logs"].append({
        "timestamp": time.strftime("%H:%M:%S"),
        "type": log_type,
        "content": content
    })

# --- æ ¸å¿ƒèŠ‚ç‚¹é€»è¾‘ ---

def perception_node(state: AgentState) -> AgentState:
    """æ„ŸçŸ¥èŠ‚ç‚¹ï¼šæå–æ„å›¾"""
    print("ğŸ” [Perception] Extracting intent & locations...")
    
    if not state.get("messages"):
        state["messages"] = [HumanMessage(content=state["user_request"])]
    
    user_request = state["user_request"]
    
    # ç®€å•çš„ JSON æå– Prompt
    prompt = f"""Extract origin and destination from: "{user_request}".
Return JSON ONLY: {{"origin": "...", "destination": "..."}}. 
If unknown, use empty string."""
    
    try:
        response = llm.invoke(prompt)
        # æš´åŠ›æ¸…æ´—
        content = response.content.strip().replace("```json", "").replace("```", "")
        match = re.search(r"\{.*?\}", content, re.DOTALL)
        if match:
            data = json.loads(match.group(0))
            state["origin"] = data.get("origin", "")
            state["destination"] = data.get("destination", "")
            print(f"   ğŸ“ Extracted: {state['origin']} -> {state['destination']}")
    except Exception as e:
        print(f"   âš ï¸ Perception failed: {e}")

    state["current_step"] = "perception"
    return state

def planning_node(state: AgentState) -> AgentState:
    """è§„åˆ’èŠ‚ç‚¹ï¼šæ‰‹åŠ¨ Prompt é©±åŠ¨å·¥å…·è°ƒç”¨"""
    retry_count = state.get("retry_count", 0)
    print(f"ğŸ“‹ [Planning] Reasoning... (attempt {retry_count + 1})")
    
    # ============================================================
    # æ ¸å¿ƒä¿®æ”¹ï¼šConstruct "Text-to-JSON" Prompt
    # ============================================================
    system_instruction = f"""ä½ æ˜¯ä¸€ä¸ªäº¤é€šæ™ºèƒ½ä½“ã€‚
ã€å¯ç”¨å·¥å…·ã€‘
{TOOL_DESC}

ã€ä»»åŠ¡ã€‘
è¯·åˆ†æç”¨æˆ·é—®é¢˜ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ã€‚
å¦‚æœéœ€è¦ï¼Œ**å¿…é¡»**ä»…è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "tool": "å·¥å…·åç§°",
    "args": {{ "å‚æ•°å": "å‚æ•°å€¼" }}
}}

**ç¦æ­¢äº‹é¡¹**ï¼š
1. ä¸è¦è¾“å‡ºä»»ä½•Markdownæ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚
2. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
3. å¦‚æœç”¨æˆ·é—®è·¯ï¼Œå¿…é¡»è°ƒç”¨ `route_planning`ã€‚
4. å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¾“å‡º "DIRECT_ANSWER: ä½ çš„å›ç­”"ã€‚
"""
    if state.get("origin"):
        system_instruction += f"\n[å·²çŸ¥ä¿¡æ¯] èµ·ç‚¹:{state['origin']} ç»ˆç‚¹:{state['destination']}"

    # æ„å»ºæ¶ˆæ¯ (é˜²æ­¢ 400 Error)
    messages = list(state.get("messages", []))
    if messages and isinstance(messages[0], HumanMessage):
        if "ã€å¯ç”¨å·¥å…·ã€‘" not in messages[0].content:
            messages[0] = HumanMessage(content=f"{system_instruction}\n\nç”¨æˆ·è¾“å…¥ï¼š{messages[0].content}")
    else:
        messages = [HumanMessage(content=f"{system_instruction}\n\nç”¨æˆ·è¾“å…¥ï¼š{state['user_request']}")]

    # è°ƒç”¨æ™®é€š LLM (ä¸å¸¦ bind_tools)
    try:
        response = llm.invoke(messages)
        content = response.content.strip()
        print(f"   ğŸ“ Raw LLM Output: {content[:100]}...")
    except Exception as e:
        print(f"   âŒ LLM Error: {e}")
        response = AIMessage(content="API Error")
        content = ""

    state["messages"].append(response)
    
    # ============================================================
    # æ ¸å¿ƒä¿®æ”¹ï¼šæ‰‹åŠ¨è§£æ JSON (Manual Parsing)
    # ============================================================
    outputs = state.get("tool_outputs", [])
    tool_called = False

    # å°è¯•å¯»æ‰¾ JSON ç»“æ„
    json_match = re.search(r"\{.*\}", content.replace("\n", ""), re.DOTALL)
    
    if json_match and "DIRECT_ANSWER" not in content:
        try:
            tool_data = json.loads(json_match.group(0))
            tool_name = tool_data.get("tool")
            tool_args = tool_data.get("args", {})
            
            if tool_name in TOOL_MAP:
                print(f"   ğŸ› ï¸ Manually Executing: {tool_name} with {tool_args}")
                tool_func = TOOL_MAP[tool_name]
                
                # æ‰§è¡Œå·¥å…·
                tool_output = tool_func.invoke(tool_args)
                outputs.append({"tool": tool_name, "output": tool_output})
                
                # ä¼ªé€ ä¸€ä¸ª ToolMessage (ä¸ºäº†ä¿æŒ State ç»“æ„ä¸€è‡´æ€§)
                state["messages"].append(ToolMessage(
                    content=str(tool_output),
                    tool_call_id=f"manual_{int(time.time())}", # ä¼ªé€  ID
                    name=tool_name
                ))
                tool_called = True
            else:
                print(f"   âš ï¸ Unknown tool in JSON: {tool_name}")
        except json.JSONDecodeError:
            print("   âš ï¸ JSON Parse Failed")
    
    if not tool_called:
        print("   âš ï¸ No valid JSON tool call found.")

    state["tool_outputs"] = outputs
    state["current_step"] = "planning"
    return state

def reflection_node(state: AgentState) -> AgentState:
    """åæ€èŠ‚ç‚¹"""
    print("ğŸ¤” [Reflection] Reviewing...")
    retry_count = state.get("retry_count", 0) + 1
    state["retry_count"] = retry_count
    
    # åªè¦æœ‰å·¥å…·è¾“å‡ºï¼Œæˆ–è€…é‡è¯•æ¬¡æ•°å¤Ÿäº†ï¼Œå°±é€šè¿‡
    if state.get("tool_outputs") or retry_count >= MAX_RETRY_COUNT:
        state["reflection_score"] = 1.0
    else:
        state["reflection_score"] = 0.0
        print("   ğŸ›‘ No tools used, injecting critique...")
        # æ³¨å…¥æ›´æ˜ç¡®çš„ Prompt
        state["messages"].append(HumanMessage(
            content="Error: You did not output the required JSON tool call. Please output JSON ONLY: {\"tool\": \"route_planning\", \"args\": {...}}"
        ))

    state["current_step"] = "reflection"
    return state

def output_node(state: AgentState) -> AgentState:
    """è¾“å‡ºèŠ‚ç‚¹"""
    print("âœ… [Output] Generating report...")
    context = json.dumps(state.get('tool_outputs', []), ensure_ascii=False)
    prompt = f"æ ¹æ®ä»¥ä¸‹æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ï¼ˆå¦‚æœæ˜¯JSONæ•°æ®è¯·è§£è¯»å®ƒï¼‰ã€‚\næ•°æ®ï¼š{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{state['user_request']}"
    
    response = llm.invoke([HumanMessage(content=prompt)])
    state["recommendation"] = response.content
    state["messages"].append(AIMessage(content=response.content))
    state["current_step"] = "output"
    return state