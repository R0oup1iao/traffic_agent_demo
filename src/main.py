"""
æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ - FastAPI åç«¯æœåŠ¡
"""
import json
import asyncio
import time
import threading
from contextlib import asynccontextmanager
from pathlib import Path
from typing import AsyncGenerator, Optional
from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse
from pydantic import BaseModel

from .agents.traffic_agent import traffic_agent
from .agents.nodes import set_status_callback
from .core.state import AgentState


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œå¯åŠ¨æ—¶åˆå§‹åŒ– MCP Client"""
    # Startup
    try:
        from .tools.mcp_client import init_mcp_client
        await init_mcp_client()
        print("âœ… MCP Client initialized successfully")
    except Exception as e:
        print(f"âš ï¸ MCP Client initialization failed: {e}")
        print("   Continuing without MCP tools...")
    
    yield
    
    # Shutdown
    print("ğŸ›‘ Shutting down...")


# ===== App åˆå§‹åŒ– =====
app = FastAPI(
    title="æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“",
    description="åŸºäºå¤šæºå¼‚æ„äº¤é€šå¤§æ•°æ®çš„å®æ—¶è¯±å¯¼ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ",
    version="1.0.0",
    lifespan=lifespan
)

# é™æ€æ–‡ä»¶ç›®å½•
STATIC_DIR = Path(__file__).parent.parent / "static"

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# ===== å…¨å±€å˜é‡ =====
_last_debug_logs = []
_last_state = {}

# å½“å‰çŠ¶æ€ (ç”¨äºæµå¼æ¨é€)
_current_status = {
    "phase": "idle",
    "text": "",
    "detail": "",
    "updated_at": 0
}
_status_lock = threading.Lock()


def _update_current_status(phase: str, text: str, detail: str = ""):
    """æ›´æ–°å½“å‰çŠ¶æ€ (çº¿ç¨‹å®‰å…¨)"""
    global _current_status
    with _status_lock:
        _current_status = {
            "phase": phase,
            "text": text,
            "detail": detail,
            "updated_at": time.time()
        }


# ===== è¯·æ±‚/å“åº”æ¨¡å‹ =====
class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    success: bool
    recommendation: str = ""
    debug_logs: list = []
    state: dict = {}
    error: str = ""


# ===== è·¯ç”± =====

@app.get("/", response_class=HTMLResponse)
async def index():
    """è¿”å›ä¸»é¡µ"""
    index_path = STATIC_DIR / "index.html"
    return FileResponse(index_path)


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "service": "Traffic Intelligence Agent"}


@app.get("/api/status")
async def get_current_status():
    """è·å–å½“å‰ Agent çŠ¶æ€ (ç”¨äºè½®è¯¢)"""
    with _status_lock:
        return _current_status.copy()


async def generate_stream(message: str) -> AsyncGenerator[str, None]:
    """
    æµå¼ç”Ÿæˆ Agent æ‰§è¡Œè¿‡ç¨‹ï¼Œé€šè¿‡ SSE æ¨é€çŠ¶æ€æ›´æ–°
    ä½¿ç”¨ astream å®æ—¶è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
    """
    global _last_debug_logs, _last_state
    
    # é‡ç½®çŠ¶æ€
    _update_current_status("perception", "ğŸ” æ­£åœ¨æ„ŸçŸ¥ç”¨æˆ·æ„å›¾...", "åˆ†ææ‚¨çš„é—®é¢˜")
    
    # åˆå§‹åŒ– Agent çŠ¶æ€
    initial_state: AgentState = {
        "user_request": message,
        "origin": "",
        "destination": "",
        "traffic_status": "",
        "tool_outputs": [],
        "candidate_plans": [],
        "recommendation": "",
        "reflection_score": 0.0,
        "retry_count": 0,
        "messages": [],
        "current_step": "init",
        "debug_logs": []
    }
    
    # å‘é€åˆå§‹çŠ¶æ€
    yield f"data: {json.dumps({'type': 'status', 'phase': 'perception', 'text': 'ğŸ” æ­£åœ¨æ„ŸçŸ¥ç”¨æˆ·æ„å›¾...', 'detail': 'åˆ†ææ‚¨çš„é—®é¢˜'}, ensure_ascii=False)}\n\n"
    
    print(f"\n{'='*50}")
    print(f"ğŸ“¨ æ”¶åˆ°è¯·æ±‚: {message}")
    print(f"{'='*50}")
    
    # èŠ‚ç‚¹åç§°åˆ°çŠ¶æ€çš„æ˜ å°„
    node_status_map = {
        "perception": ("perception", "ğŸ” æ­£åœ¨æ„ŸçŸ¥ç”¨æˆ·æ„å›¾...", "åˆ†æç”¨æˆ·é—®é¢˜"),
        "call_model": ("planning", "ğŸ“‹ æ­£åœ¨è§„åˆ’æ–¹æ¡ˆ...", "æ¨¡å‹æ€è€ƒä¸­"),
        "tools": ("execution", "âš¡ æ­£åœ¨æ‰§è¡Œå·¥å…·...", "è°ƒç”¨å¤–éƒ¨æœåŠ¡"),
        "output": ("output", "ğŸ“ æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...", "æ•´åˆç»“æœ"),
    }
    
    final_state = None
    
    try:
        # ä½¿ç”¨ astream æµå¼è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
        async for event in traffic_agent.astream(initial_state, stream_mode="updates"):
            # event æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkey æ˜¯èŠ‚ç‚¹åç§°ï¼Œvalue æ˜¯è¯¥èŠ‚ç‚¹è¿”å›çš„çŠ¶æ€æ›´æ–°
            for node_name, node_output in event.items():
                print(f"   ğŸ“Œ Node executed: {node_name}")
                
                # è·å–å¯¹åº”çš„çŠ¶æ€ä¿¡æ¯
                if node_name in node_status_map:
                    phase, text, detail = node_status_map[node_name]
                    
                    # å¦‚æœæ˜¯ tools èŠ‚ç‚¹ï¼Œå°è¯•æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
                    if node_name == "tools":
                        messages = node_output.get("messages", [])
                        tool_names = []
                        for msg in messages:
                            if hasattr(msg, 'name'):
                                tool_names.append(msg.name)
                        if tool_names:
                            detail = f"æ‰§è¡Œ: {', '.join(tool_names)}"
                    
                    # å¦‚æœæ˜¯ call_model èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if node_name == "call_model":
                        messages = node_output.get("messages", [])
                        for msg in messages:
                            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                tool_names = [tc.get("name", "unknown") for tc in msg.tool_calls]
                                phase = "execution"
                                text = "ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·..."
                                detail = f"å·¥å…·: {', '.join(tool_names)}"
                    
                    # å‘é€çŠ¶æ€æ›´æ–°
                    status_data = {
                        'type': 'status',
                        'phase': phase,
                        'text': text,
                        'detail': detail,
                        'node': node_name
                    }
                    yield f"data: {json.dumps(status_data, ensure_ascii=False)}\n\n"
                    _update_current_status(phase, text, detail)
                
                # ä¿å­˜æœ€æ–°çŠ¶æ€
                if node_name == "output":
                    final_state = node_output
        
        # å¦‚æœæ²¡æœ‰ä» output èŠ‚ç‚¹è·å–åˆ°çŠ¶æ€ï¼Œå°è¯•è·å–å®Œæ•´çŠ¶æ€
        if final_state is None:
            # ä½¿ç”¨ ainvoke ä½œä¸ºåå¤‡
            final_state = await traffic_agent.ainvoke(initial_state)
        
        # åˆå¹¶çŠ¶æ€ï¼ˆastream åªè¿”å›æ›´æ–°ï¼Œå¯èƒ½éœ€è¦åˆå¹¶ï¼‰
        recommendation = final_state.get("recommendation", "")
        debug_logs = final_state.get("debug_logs", [])
        
        # ä¿å­˜è°ƒè¯•ä¿¡æ¯
        _last_debug_logs = debug_logs
        _last_state = {
            "user_request": message,
            "origin": final_state.get("origin", ""),
            "destination": final_state.get("destination", ""),
            "traffic_status": final_state.get("traffic_status", ""),
            "retry_count": final_state.get("retry_count", 0),
            "reflection_score": final_state.get("reflection_score", 0.0),
            "tool_outputs_count": len(final_state.get("tool_outputs", [])),
            "current_step": final_state.get("current_step", "")
        }
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š {len(recommendation)} å­—ç¬¦")
        
        # å‘é€å®ŒæˆçŠ¶æ€
        yield f"data: {json.dumps({'type': 'status', 'phase': 'execution', 'text': 'âœ… ç”Ÿæˆå®Œæˆ', 'detail': 'æ­£åœ¨è¾“å‡ºå›å¤...'}, ensure_ascii=False)}\n\n"
        
        # å‘é€æœ€ç»ˆç»“æœ
        result_data = {
            'type': 'result',
            'success': True,
            'recommendation': recommendation,
            'debug_logs': _last_debug_logs,
            'state': _last_state
        }
        yield f"data: {json.dumps(result_data, ensure_ascii=False)}\n\n"
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
    finally:
        _update_current_status("idle", "", "")


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼å¤„ç†ç”¨æˆ·èŠå¤©è¯·æ±‚ï¼Œé€šè¿‡ SSE å®æ—¶æ¨é€çŠ¶æ€
    """
    message = request.message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")
    
    return StreamingResponse(
        generate_stream(message),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    å¤„ç†ç”¨æˆ·èŠå¤©è¯·æ±‚ï¼Œè°ƒç”¨ Agent å¹¶è¿”å›ç»“æœï¼ˆéæµå¼ï¼Œä¿æŒå…¼å®¹ï¼‰
    """
    global _last_debug_logs, _last_state
    
    message = request.message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")
    
    try:
        # åˆå§‹åŒ– Agent çŠ¶æ€
        initial_state: AgentState = {
            "user_request": message,
            "origin": "",
            "destination": "",
            "traffic_status": "",
            "tool_outputs": [],
            "candidate_plans": [],
            "recommendation": "",
            "reflection_score": 0.0,
            "retry_count": 0,
            "messages": [],
            "current_step": "init",
            "debug_logs": []
        }
        
        # è¿è¡Œ Agent å›¾
        print(f"\n{'='*50}")
        print(f"ğŸ“¨ æ”¶åˆ°è¯·æ±‚: {message}")
        print(f"{'='*50}")
        
        final_state = await traffic_agent.ainvoke(initial_state)
        
        # ä¿å­˜è°ƒè¯•ä¿¡æ¯
        _last_debug_logs = final_state.get("debug_logs", [])
        _last_state = {
            "user_request": final_state.get("user_request", ""),
            "origin": final_state.get("origin", ""),
            "destination": final_state.get("destination", ""),
            "traffic_status": final_state.get("traffic_status", ""),
            "retry_count": final_state.get("retry_count", 0),
            "reflection_score": final_state.get("reflection_score", 0.0),
            "tool_outputs_count": len(final_state.get("tool_outputs", [])),
            "current_step": final_state.get("current_step", "")
        }
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š {len(final_state['recommendation'])} å­—ç¬¦")
        
        return ChatResponse(
            success=True,
            recommendation=final_state["recommendation"],
            debug_logs=_last_debug_logs,
            state=_last_state
        )
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return ChatResponse(
            success=False,
            error=str(e)
        )


@app.get("/api/debug")
async def get_debug_info():
    """è·å–æœ€åä¸€æ¬¡è¿è¡Œçš„è°ƒè¯•ä¿¡æ¯"""
    global _last_debug_logs, _last_state
    
    return {
        "debug_logs": _last_debug_logs,
        "state": _last_state
    }


# ===== å¯åŠ¨å…¥å£ =====
def main():
    """å¯åŠ¨æœåŠ¡"""
    import uvicorn
    print("\n" + "="*60)
    print("ğŸš¦ æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ - æœåŠ¡å¯åŠ¨ä¸­...")
    print("="*60)
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:8000")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print("="*60 + "\n")
    
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )


if __name__ == "__main__":
    main()
