import gradio as gr
import json
from .agents.traffic_agent import traffic_agent
from .core.state import AgentState

# å…¨å±€å˜é‡å­˜å‚¨æœ€åä¸€æ¬¡è¿è¡Œçš„è°ƒè¯•æ—¥å¿—
_last_debug_logs = []
_last_state = {}

def run_agent_workflow(message, history):
    """
    Interface between Gradio and the LangGraph Agent.
    """
    global _last_debug_logs, _last_state
    
    initial_state: AgentState = {
        "user_request": message,
        "origin": "",
        "destination": "",
        "traffic_status": "",
        "tool_outputs": [],
        "candidate_plans": [],
        "recommendation": "",
        "reflection_score": 0.0,
        "retry_count": 0,
        "messages": [],
        "current_step": "init",
        "debug_logs": []
    }
    
    # Run the graph
    final_state = traffic_agent.invoke(initial_state)
    
    # ä¿å­˜è°ƒè¯•ä¿¡æ¯ä¾› Debug é¡µé¢ä½¿ç”¨
    _last_debug_logs = final_state.get("debug_logs", [])
    _last_state = {
        "user_request": final_state.get("user_request", ""),
        "origin": final_state.get("origin", ""),
        "destination": final_state.get("destination", ""),
        "traffic_status": final_state.get("traffic_status", ""),
        "retry_count": final_state.get("retry_count", 0),
        "reflection_score": final_state.get("reflection_score", 0.0),
        "tool_outputs_count": len(final_state.get("tool_outputs", [])),
        "current_step": final_state.get("current_step", "")
    }
    
    return final_state["recommendation"]

def get_debug_info():
    """è·å–è°ƒè¯•ä¿¡æ¯"""
    global _last_debug_logs, _last_state
    
    if not _last_debug_logs:
        return "å°šæ— è°ƒè¯•ä¿¡æ¯ã€‚è¯·å…ˆåœ¨ä¸»ç•Œé¢å‘é€ä¸€æ¡æ¶ˆæ¯ã€‚", "{}"
    
    # æ ¼å¼åŒ–è°ƒè¯•æ—¥å¿—
    log_lines = []
    for log in _last_debug_logs:
        timestamp = log.get("timestamp", "??:??:??")
        log_type = log.get("type", "unknown")
        content = log.get("content", {})
        
        # æ ¹æ®ç±»å‹æ ¼å¼åŒ–
        if log_type == "llm_response":
            log_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            log_lines.append(f"ğŸ¤– [{timestamp}] LLM å“åº” (è€—æ—¶: {content.get('elapsed_time', '?')})")
            log_lines.append(f"ğŸ“ å†…å®¹: {content.get('content', '(æ— )')}")
            if content.get("tool_calls"):
                log_lines.append(f"ğŸ› ï¸ å·¥å…·è°ƒç”¨:")
                for tc in content["tool_calls"]:
                    log_lines.append(f"   â€¢ {tc['name']}: {json.dumps(tc['args'], ensure_ascii=False)}")
        elif log_type == "tool_execution":
            log_lines.append(f"âœ… [{timestamp}] å·¥å…·æ‰§è¡Œ: {content.get('tool', '?')}")
            log_lines.append(f"   å‚æ•°: {json.dumps(content.get('args', {}), ensure_ascii=False)}")
            log_lines.append(f"   ç»“æœ: {json.dumps(content.get('output', {}), ensure_ascii=False, indent=2)}")
        elif log_type == "reflection":
            score = content.get("reflection_score", 0)
            status = "âœ… é€šè¿‡" if score >= 0.6 else "âš ï¸ éœ€é‡è¯•"
            log_lines.append(f"ğŸ¤” [{timestamp}] åæ€è¯„ä¼°: {status}")
            log_lines.append(f"   é‡è¯•æ¬¡æ•°: {content.get('retry_count', 0)}, åˆ†æ•°: {score}")
        elif log_type == "perception":
            log_lines.append(f"ğŸ” [{timestamp}] æ„ŸçŸ¥: {content.get('origin', '?')} â†’ {content.get('destination', '?')}")
        elif log_type == "final_output":
            log_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            log_lines.append(f"ğŸ“„ [{timestamp}] æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ (è€—æ—¶: {content.get('elapsed_time', '?')}, é•¿åº¦: {content.get('report_length', 0)} å­—ç¬¦)")
        elif log_type == "no_tool_calls":
            log_lines.append(f"â„¹ï¸ [{timestamp}] {content.get('note', 'LLMæœªè°ƒç”¨å·¥å…·')}")
        elif log_type == "tool_error":
            log_lines.append(f"âŒ [{timestamp}] å·¥å…·é”™è¯¯: {content.get('tool', '?')}")
            log_lines.append(f"   é”™è¯¯: {content.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            log_lines.append(f"ğŸ“‹ [{timestamp}] {log_type}: {json.dumps(content, ensure_ascii=False)}")
    
    debug_log_text = "\n".join(log_lines) if log_lines else "æ— è°ƒè¯•æ—¥å¿—"
    state_json = json.dumps(_last_state, ensure_ascii=False, indent=2)
    
    return debug_log_text, state_json

def create_ui():
    """
    Creates the professional Gradio UI for the Traffic Agent with Debug tab.
    """
    with gr.Blocks(
        title="ğŸš¦ æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ (å·¥ç¨‹åŒ– Demo)"
    ) as demo:
        gr.Markdown("""
        # ğŸš¦ æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“
        ### åŸºäºå¤šæºå¼‚æ„äº¤é€šå¤§æ•°æ®çš„å®æ—¶è¯±å¯¼ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ
        
        æœ¬ç³»ç»Ÿé›†æˆäº†åšå£«è®ºæ–‡ä¸­çš„æ ¸å¿ƒç ”ç©¶æˆæœï¼š
        *   **æ—¶ç©ºé¢„æµ‹**ï¼šåŸºäº Transformer çš„è·¯ç½‘çŠ¶æ€é¢„è®­ç»ƒ (Chap 1)
        *   **å¼‚å¸¸æ„ŸçŸ¥**ï¼šå¤šæ¨¡æ€äº¤é€šå¼‚å¸¸æ£€æµ‹ (Chap 2)
        *   **å› æœåˆ†æ**ï¼šGeoDCD åŠ¨æ€å› æœä¼ æ’­åˆ†æ (Chap 3)
        *   **å‡ºè¡Œæ¨è**ï¼šCDHGNN å¯¹æ¯”å»åå¼‚æ„å›¾ç¥ç»ç½‘ç»œ (Chap 4)
        """)
        
        with gr.Tabs():
            # ä¸»èŠå¤©ç•Œé¢
            with gr.TabItem("ğŸ’¬ æ™ºèƒ½å¯¹è¯", id="chat"):
                chatbot = gr.ChatInterface(
                    fn=run_agent_workflow,
                    examples=["ä»åŒ—äº¬å—ç«™åˆ°æ¸…åå¤§å­¦æ€ä¹ˆèµ°ï¼Ÿ", "è¥¿äºŒç¯å‘ç”Ÿäº‹æ•…ï¼Œå¯¹æˆ‘å»æœºåœºæœ‰å½±å“å—ï¼Ÿ", "é¢„æµ‹æ˜å¤©å‘¨ä¸€æ—©é«˜å³°çš„é€šè¡ŒçŠ¶å†µ"],
                    title=None
                )
            
            # Debug é¡µé¢
            with gr.TabItem("ğŸ› è°ƒè¯•ä¿¡æ¯", id="debug"):
                gr.Markdown("### è°ƒè¯•é¢æ¿\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®åˆ·æ–°ï¼ŒæŸ¥çœ‹æœ€è¿‘ä¸€æ¬¡è¯·æ±‚çš„å®Œæ•´ LLM è¾“å‡ºå’Œæ‰§è¡Œæ—¥å¿—ã€‚")
                
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°è°ƒè¯•ä¿¡æ¯", variant="primary")
                
                with gr.Row():
                    with gr.Column(scale=2):
                        debug_logs = gr.Textbox(
                            label="ğŸ“‹ æ‰§è¡Œæ—¥å¿— (LLM è¾“å‡º / å·¥å…·è°ƒç”¨)",
                            lines=20,
                            max_lines=30,
                            interactive=False
                        )
                    with gr.Column(scale=1):
                        state_info = gr.JSON(
                            label="ğŸ“Š æœ€ç»ˆçŠ¶æ€æ‘˜è¦"
                        )
                
                refresh_btn.click(
                    fn=get_debug_info,
                    outputs=[debug_logs, state_info]
                )
        
        gr.Markdown("""
        ---
        **æŠ€æœ¯æ ˆ**: LangGraph + OpenAI Gemini-3-Flash + Gaode Maps API + UV Package Manager
        """)
        
    return demo

if __name__ == "__main__":
    ui = create_ui()
    ui.launch(server_name="0.0.0.0", server_port=7860)

