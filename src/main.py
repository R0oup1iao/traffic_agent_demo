"""
æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ - FastAPI åç«¯æœåŠ¡
"""
import json
import asyncio
import time
import threading
from pathlib import Path
from typing import AsyncGenerator, Optional
from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse
from pydantic import BaseModel

from .agents.traffic_agent import traffic_agent
from .agents.nodes import set_status_callback
from .core.state import AgentState

# ===== App åˆå§‹åŒ– =====
app = FastAPI(
    title="æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“",
    description="åŸºäºå¤šæºå¼‚æ„äº¤é€šå¤§æ•°æ®çš„å®æ—¶è¯±å¯¼ä¸å†³ç­–æ”¯æŒç³»ç»Ÿ",
    version="1.0.0"
)

# é™æ€æ–‡ä»¶ç›®å½•
STATIC_DIR = Path(__file__).parent.parent / "static"

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# ===== å…¨å±€å˜é‡ =====
_last_debug_logs = []
_last_state = {}

# å½“å‰çŠ¶æ€ (ç”¨äºæµå¼æ¨é€)
_current_status = {
    "phase": "idle",
    "text": "",
    "detail": "",
    "updated_at": 0
}
_status_lock = threading.Lock()


def _update_current_status(phase: str, text: str, detail: str = ""):
    """æ›´æ–°å½“å‰çŠ¶æ€ (çº¿ç¨‹å®‰å…¨)"""
    global _current_status
    with _status_lock:
        _current_status = {
            "phase": phase,
            "text": text,
            "detail": detail,
            "updated_at": time.time()
        }


# ===== è¯·æ±‚/å“åº”æ¨¡å‹ =====
class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    success: bool
    recommendation: str = ""
    debug_logs: list = []
    state: dict = {}
    error: str = ""


# ===== è·¯ç”± =====

@app.get("/", response_class=HTMLResponse)
async def index():
    """è¿”å›ä¸»é¡µ"""
    index_path = STATIC_DIR / "index.html"
    return FileResponse(index_path)


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "service": "Traffic Intelligence Agent"}


@app.get("/api/status")
async def get_current_status():
    """è·å–å½“å‰ Agent çŠ¶æ€ (ç”¨äºè½®è¯¢)"""
    with _status_lock:
        return _current_status.copy()


async def generate_stream(message: str) -> AsyncGenerator[str, None]:
    """
    æµå¼ç”Ÿæˆ Agent æ‰§è¡Œè¿‡ç¨‹ï¼Œé€šè¿‡ SSE æ¨é€çŠ¶æ€æ›´æ–°
    """
    global _last_debug_logs, _last_state
    
    # é‡ç½®çŠ¶æ€
    _update_current_status("perception", "ğŸ” æ­£åœ¨æ„ŸçŸ¥ç”¨æˆ·æ„å›¾...", "åˆ†ææ‚¨çš„é—®é¢˜")
    
    # åˆå§‹åŒ– Agent çŠ¶æ€
    initial_state: AgentState = {
        "user_request": message,
        "origin": "",
        "destination": "",
        "traffic_status": "",
        "tool_outputs": [],
        "candidate_plans": [],
        "recommendation": "",
        "reflection_score": 0.0,
        "retry_count": 0,
        "messages": [],
        "current_step": "init",
        "debug_logs": []
    }
    
    # å‘é€åˆå§‹çŠ¶æ€
    yield f"data: {json.dumps({'type': 'status', 'phase': 'perception', 'text': 'ğŸ” æ­£åœ¨æ„ŸçŸ¥ç”¨æˆ·æ„å›¾...', 'detail': 'åˆ†ææ‚¨çš„é—®é¢˜'})}\n\n"
    
    print(f"\n{'='*50}")
    print(f"ğŸ“¨ æ”¶åˆ°è¯·æ±‚: {message}")
    print(f"{'='*50}")
    
    # è®¾ç½®çŠ¶æ€å›è°ƒ
    last_sent_status = {"phase": "perception", "text": "", "detail": ""}
    
    def on_status_change(phase: str, text: str, detail: str = ""):
        _update_current_status(phase, text, detail)
    
    set_status_callback(on_status_change)
    
    try:
        # åœ¨åå°çº¿ç¨‹è¿è¡Œ Agent
        import concurrent.futures
        result_holder = {"final_state": None, "error": None}
        
        def run_agent():
            try:
                result_holder["final_state"] = traffic_agent.invoke(initial_state)
            except Exception as e:
                result_holder["error"] = str(e)
                import traceback
                traceback.print_exc()
        
        executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
        future = executor.submit(run_agent)
        
        # è½®è¯¢çŠ¶æ€æ›´æ–°å¹¶æ¨é€
        while not future.done():
            await asyncio.sleep(0.2)  # 200ms è½®è¯¢é—´éš”
            
            with _status_lock:
                current = _current_status.copy()
            
            # åªæœ‰çŠ¶æ€å˜åŒ–æ—¶æ‰æ¨é€
            if (current["phase"] != last_sent_status["phase"] or 
                current["text"] != last_sent_status["text"]):
                yield f"data: {json.dumps({'type': 'status', 'phase': current['phase'], 'text': current['text'], 'detail': current['detail']})}\n\n"
                last_sent_status = current.copy()
        
        # ç­‰å¾…å®Œæˆ
        future.result()
        executor.shutdown(wait=False)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if result_holder["error"]:
            yield f"data: {json.dumps({'type': 'error', 'error': result_holder['error']})}\n\n"
            return
        
        final_state = result_holder["final_state"]
        
        # ä¿å­˜è°ƒè¯•ä¿¡æ¯
        _last_debug_logs = final_state.get("debug_logs", [])
        _last_state = {
            "user_request": final_state.get("user_request", ""),
            "origin": final_state.get("origin", ""),
            "destination": final_state.get("destination", ""),
            "traffic_status": final_state.get("traffic_status", ""),
            "retry_count": final_state.get("retry_count", 0),
            "reflection_score": final_state.get("reflection_score", 0.0),
            "tool_outputs_count": len(final_state.get("tool_outputs", [])),
            "current_step": final_state.get("current_step", "")
        }
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š {len(final_state['recommendation'])} å­—ç¬¦")
        
        # å‘é€å®ŒæˆçŠ¶æ€
        yield f"data: {json.dumps({'type': 'status', 'phase': 'execution', 'text': 'âœ… ç”Ÿæˆå®Œæˆ', 'detail': 'æ­£åœ¨è¾“å‡ºå›å¤...'})}\n\n"
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield f"data: {json.dumps({'type': 'result', 'success': True, 'recommendation': final_state['recommendation'], 'debug_logs': _last_debug_logs, 'state': _last_state})}\n\n"
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
    finally:
        # æ¸…é™¤å›è°ƒ
        set_status_callback(None)
        _update_current_status("idle", "", "")


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼å¤„ç†ç”¨æˆ·èŠå¤©è¯·æ±‚ï¼Œé€šè¿‡ SSE å®æ—¶æ¨é€çŠ¶æ€
    """
    message = request.message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")
    
    return StreamingResponse(
        generate_stream(message),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    å¤„ç†ç”¨æˆ·èŠå¤©è¯·æ±‚ï¼Œè°ƒç”¨ Agent å¹¶è¿”å›ç»“æœï¼ˆéæµå¼ï¼Œä¿æŒå…¼å®¹ï¼‰
    """
    global _last_debug_logs, _last_state
    
    message = request.message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="æ¶ˆæ¯ä¸èƒ½ä¸ºç©º")
    
    try:
        # åˆå§‹åŒ– Agent çŠ¶æ€
        initial_state: AgentState = {
            "user_request": message,
            "origin": "",
            "destination": "",
            "traffic_status": "",
            "tool_outputs": [],
            "candidate_plans": [],
            "recommendation": "",
            "reflection_score": 0.0,
            "retry_count": 0,
            "messages": [],
            "current_step": "init",
            "debug_logs": []
        }
        
        # è¿è¡Œ Agent å›¾
        print(f"\n{'='*50}")
        print(f"ğŸ“¨ æ”¶åˆ°è¯·æ±‚: {message}")
        print(f"{'='*50}")
        
        final_state = traffic_agent.invoke(initial_state)
        
        # ä¿å­˜è°ƒè¯•ä¿¡æ¯
        _last_debug_logs = final_state.get("debug_logs", [])
        _last_state = {
            "user_request": final_state.get("user_request", ""),
            "origin": final_state.get("origin", ""),
            "destination": final_state.get("destination", ""),
            "traffic_status": final_state.get("traffic_status", ""),
            "retry_count": final_state.get("retry_count", 0),
            "reflection_score": final_state.get("reflection_score", 0.0),
            "tool_outputs_count": len(final_state.get("tool_outputs", [])),
            "current_step": final_state.get("current_step", "")
        }
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š {len(final_state['recommendation'])} å­—ç¬¦")
        
        return ChatResponse(
            success=True,
            recommendation=final_state["recommendation"],
            debug_logs=_last_debug_logs,
            state=_last_state
        )
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return ChatResponse(
            success=False,
            error=str(e)
        )


@app.get("/api/debug")
async def get_debug_info():
    """è·å–æœ€åä¸€æ¬¡è¿è¡Œçš„è°ƒè¯•ä¿¡æ¯"""
    global _last_debug_logs, _last_state
    
    return {
        "debug_logs": _last_debug_logs,
        "state": _last_state
    }


# ===== å¯åŠ¨å…¥å£ =====
def main():
    """å¯åŠ¨æœåŠ¡"""
    import uvicorn
    print("\n" + "="*60)
    print("ğŸš¦ æ™ºæ…§äº¤é€šè¯±å¯¼æ™ºèƒ½ä½“ - æœåŠ¡å¯åŠ¨ä¸­...")
    print("="*60)
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:8000")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print("="*60 + "\n")
    
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )


if __name__ == "__main__":
    main()
